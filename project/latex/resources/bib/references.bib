@inproceedings{jadlovska2012classical,
    title={Classical double inverted pendulumâ€”A complex overview of a system},
    author={Jadlovska, Slavka and Sarnovsky, Jan},
    booktitle={2012 IEEE 10th International Symposium on Applied Machine Intelligence and Informatics (SAMI)},
    pages={103--108},
    year={2012},
    organization={IEEE}
}

@book{zhang2007fault,
    title={Fault Detection, Supervision and Safety of Technical Processes 2006: A Proceedings Volume from the 6th IFAC Symposium on Fault Detection, Supervision and Safety of Technical Processes},
    author={Zhang, Hong-Yue},
    year={2007},
    publisher={Elsevier}
}

@article{ernst2005tree,
    title={Tree-based batch mode reinforcement learning},
    author={Ernst, Damien and Geurts, Pierre and Wehenkel, Louis},
    journal={Journal of Machine Learning Research},
    volume={6},
    pages={503--556},
    year={2005},
    publisher={Microtome Publishing}
}

@inproceedings{silver2014deterministic,
    title={Deterministic policy gradient algorithms},
    author={Silver, David and Lever, Guy and Heess, Nicolas and Degris, Thomas and Wierstra, Daan and Riedmiller, Martin},
    booktitle={International conference on machine learning},
    pages={387--395},
    year={2014},
    organization={PMLR}
}

@article{lillicrap2015continuous,
    title={Continuous control with deep reinforcement learning},
    author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
    journal={arXiv preprint arXiv:1509.02971},
    year={2015}
}

@article{bogdanov2004optimal,
    title={Optimal control of a double inverted pendulum on a cart},
    author={Bogdanov, Alexander},
    journal={Oregon Health and Science University, Tech. Rep. CSE-04-006, OGI School of Science and Engineering, Beaverton, OR},
    year={2004}
}

@misc{ddpgopenai,
    title={Deep Deterministic Policy Gradient},
    author={OpenAI Spinning Up},
    url={https://spinningup.openai.com/en/latest/algorithms/ddpg.html}
}

@misc{ddpgtds,
    title={Deep Deterministic Policy Gradients Explained},
    author={Chris Yoon},
    url={https://towardsdatascience.com/deep-deterministic-policy-gradients-explained-2d94655a9b7b}
}

@misc{bollandinfo80031,
    title={Gradient-based techniques for reinforcement learning in continuous domains (finite time control)},
    author={Adrien Bolland},
    url={http://blogs.ulg.ac.be/damien-ernst/wp-content/uploads/sites/9/2021/03/rl_course_1.pdf}
}

@misc{bollandinfo80032,
    title={Gradient-based techniques for reinforcement learning in continuous domains (infinite time control)},
    author={Adrien Bolland},
    url={http://blogs.ulg.ac.be/damien-ernst/wp-content/uploads/sites/9/2021/03/pg-part-2.pdf}
}

@book{sutton2018reinforcement,
    title={Reinforcement learning: An introduction},
    author={Sutton, Richard S and Barto, Andrew G},
    year={2018},
    publisher={MIT press}
}

@article{kingma2014adam,
    title={Adam: A method for stochastic optimization},
    author={Kingma, Diederik P and Ba, Jimmy},
    journal={arXiv preprint arXiv:1412.6980},
    year={2014}
}

@article{polyak1992acceleration,
    title={Acceleration of stochastic approximation by averaging},
    author={Polyak, Boris T and Juditsky, Anatoli B},
    journal={SIAM journal on control and optimization},
    volume={30},
    number={4},
    pages={838--855},
    year={1992},
    publisher={SIAM}
}

@article{dulac2015deep,
    title={Deep reinforcement learning in large discrete action spaces},
    author={Dulac-Arnold, Gabriel and Evans, Richard and van Hasselt, Hado and Sunehag, Peter and Lillicrap, Timothy and Hunt, Jonathan and Mann, Timothy and Weber, Theophane and Degris, Thomas and Coppin, Ben},
    journal={arXiv preprint arXiv:1512.07679},
    year={2015}
}

@article{clevert2015fast,
    title={Fast and accurate deep network learning by exponential linear units (elus)},
    author={Clevert, Djork-Arne and Unterthiner, Thomas and Hochreiter, Sepp},
    journal={arXiv preprint arXiv:1511.07289},
    year={2015}
}

@article{hou2019improving,
    title={Improving DDPG via Prioritized Experience Replay},
    author={Hou, Yuenan and Zhang, Yi},
    journal={no. May},
    year={2019}
}

@inproceedings{mnih2016asynchronous,
    title={Asynchronous methods for deep reinforcement learning},
    author={Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
    booktitle={International conference on machine learning},
    pages={1928--1937},
    year={2016},
    organization={PMLR}
}

@misc{mediumddpgimprovements,
    title={Improvements},
    author={KT2713},
    url={https://medium.com/robotic-arm-control-using-deep-reinforcement/improvements-b2de257617dc}
}

@article{barth2018distributed,
    title={Distributed distributional deterministic policy gradients},
    author={Barth-Maron, Gabriel and Hoffman, Matthew W and Budden, David and Dabney, Will and Horgan, Dan and Tb, Dhruva and Muldal, Alistair and Heess, Nicolas and Lillicrap, Timothy},
    journal={arXiv preprint arXiv:1804.08617},
    year={2018}
}
